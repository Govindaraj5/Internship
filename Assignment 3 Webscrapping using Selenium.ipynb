{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa47a0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56672d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required packages\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae03a2",
   "metadata": {},
   "source": [
    "#Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "af9e8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the webdriver for chrom which already downloaded and kept in working environment \n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver\n",
    "# 1. First get the webpage https://www.naukri.com/\n",
    "driver.get('https://www.naukri.com/')\n",
    "#2 Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field\n",
    "Enter_job_title=driver.find_element_by_class_name('suggestor-input')\n",
    "Enter_job_title.send_keys('Data Analyst')\n",
    "\n",
    "job_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "job_location.send_keys('Bangalore')\n",
    "\n",
    "#3. Then click the search button\n",
    "search_click=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_click.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "edbd6c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data Analyst I', 'Hiring For Data Analyst I(SQL & Python)', 'Senior Data Analyst', 'Senior Data Analyst II', 'Senior Data Analyst', 'Senior Data Analyst II', 'Senior Data Analyst II', 'Looking For Data Analyst - Remote Support', 'Job openings For Data Analyst - AOA', 'Cargill - Data Analyst - Corporate Audit Domain II']\n",
      "\n",
      "\n",
      "['Cerner', 'Clario India Pvt Ltd', 'Capco', 'Flipkart', 'Flipkart', 'Flipkart', 'Flipkart', 'Locuz Enterprise Solutions Ltd', 'izmo ltd', 'Cargill Business Services India Private Limited']\n",
      "\n",
      "\n",
      "['Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Bangalore', 'Hyderabad', 'Bangalore', 'Bangalore']\n",
      "\n",
      "\n",
      "['At least 4 years Additional work experience directly related to the duties of the job a...', '1. Should have minimum 1year of hands in experience in SQL and Python2. Data Analytics ...', 'Perform Data Analysis to develop data sourcing requirement Good understanding of data g...', 'Bachelors in Engineering, Computer Science, Math, or related discipline from a reputed ...', 'Along with this, you will be expected to have a very good handle on different data stre...', 'Able to envision & implement the optimal data modeling, physical design, performance op...', 'Able to envision & implement the optimal data modeling, physical design, performance op...', 'Job SummaryDevelop data-driven insights to make decisions on talent, workforce processe...', 'Graduate in any stream and / or equivalentQualifications required: Any Bachelors degree...', 'Shift : EMEA (12PM TO 9PM) Bachelors degree in a related field or equivalent experience...']\n",
      "\n",
      "\n",
      "10 10 10 10\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Cerner</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>At least 4 years Additional work experience di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Data Analyst I(SQL &amp; Python)</td>\n",
       "      <td>Clario India Pvt Ltd</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>1. Should have minimum 1year of hands in exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Capco</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Perform Data Analysis to develop data sourcing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Bachelors in Engineering, Computer Science, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Along with this, you will be expected to have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Able to envision &amp; implement the optimal data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Analyst II</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Able to envision &amp; implement the optimal data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Looking For Data Analyst - Remote Support</td>\n",
       "      <td>Locuz Enterprise Solutions Ltd</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Job SummaryDevelop data-driven insights to mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Job openings For Data Analyst - AOA</td>\n",
       "      <td>izmo ltd</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Graduate in any stream and / or equivalentQual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cargill - Data Analyst - Corporate Audit Domai...</td>\n",
       "      <td>Cargill Business Services India Private Limited</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Shift : EMEA (12PM TO 9PM) Bachelors degree in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                     Data Analyst I   \n",
       "1            Hiring For Data Analyst I(SQL & Python)   \n",
       "2                                Senior Data Analyst   \n",
       "3                             Senior Data Analyst II   \n",
       "4                                Senior Data Analyst   \n",
       "5                             Senior Data Analyst II   \n",
       "6                             Senior Data Analyst II   \n",
       "7          Looking For Data Analyst - Remote Support   \n",
       "8                Job openings For Data Analyst - AOA   \n",
       "9  Cargill - Data Analyst - Corporate Audit Domai...   \n",
       "\n",
       "                                      company_name Job_location  \\\n",
       "0                                           Cerner    Bangalore   \n",
       "1                             Clario India Pvt Ltd    Bangalore   \n",
       "2                                            Capco    Bangalore   \n",
       "3                                         Flipkart    Bangalore   \n",
       "4                                         Flipkart    Bangalore   \n",
       "5                                         Flipkart    Bangalore   \n",
       "6                                         Flipkart    Bangalore   \n",
       "7                   Locuz Enterprise Solutions Ltd    Hyderabad   \n",
       "8                                         izmo ltd    Bangalore   \n",
       "9  Cargill Business Services India Private Limited    Bangalore   \n",
       "\n",
       "                                 experience_Required  \n",
       "0  At least 4 years Additional work experience di...  \n",
       "1  1. Should have minimum 1year of hands in exper...  \n",
       "2  Perform Data Analysis to develop data sourcing...  \n",
       "3  Bachelors in Engineering, Computer Science, Ma...  \n",
       "4  Along with this, you will be expected to have ...  \n",
       "5  Able to envision & implement the optimal data ...  \n",
       "6  Able to envision & implement the optimal data ...  \n",
       "7  Job SummaryDevelop data-driven insights to mak...  \n",
       "8  Graduate in any stream and / or equivalentQual...  \n",
       "9  Shift : EMEA (12PM TO 9PM) Bachelors degree in...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#4.Then scrape the data for the first 10 jobs results you get\n",
    "Job_title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "jobs=[]\n",
    "\n",
    "for i in Job_title:\n",
    "    jobs.append(i.text)\n",
    "    \n",
    "jtitle=jobs[0:10]\n",
    "print(jtitle)\n",
    "print('\\n')\n",
    "\n",
    "company=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "company_name=[]\n",
    "\n",
    "for i in company:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "company=company_name[0:10]\n",
    "print(company)\n",
    "print('\\n')\n",
    "\n",
    "location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "job_location=[]\n",
    "for i in location:\n",
    "    job_location.append(i.text.split('/')[0])\n",
    "    \n",
    "jlocation=job_location[0:10]\n",
    "print(jlocation)\n",
    "print('\\n')\n",
    "\n",
    "exp=driver.find_elements_by_xpath('//div[@class=\"job-description fs12 grey-text\"]')\n",
    "\n",
    "experience=[]\n",
    "for i in exp:\n",
    "    experience.append(i.text)\n",
    "    \n",
    "exp=experience[0:10]\n",
    "print(exp)\n",
    "print('\\n')\n",
    "\n",
    "print(len(jtitle),len(company),len(jlocation),len(exp))\n",
    "print('\\n')\n",
    "\n",
    "Data_analyst_df=pd.DataFrame()\n",
    "Data_analyst_df['Job_title']=jtitle\n",
    "Data_analyst_df['company_name']=company\n",
    "Data_analyst_df['Job_location']=jlocation\n",
    "Data_analyst_df['experience_Required']=exp\n",
    "\n",
    "Data_analyst_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108883a0",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e67ec0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. First get the webpage https://www.naukri.com/\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "job_desc=driver.find_element_by_class_name('suggestor-input')\n",
    "job_desc.send_keys('Data Scientist')\n",
    "\n",
    "job_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "job_location.send_keys('Bangalore')\n",
    "\n",
    "#3. Then click the search button.\n",
    "search_click=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_click.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c63111dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sr Data Scientist', 'HCL Tech Opening - Lead Data Scientist', 'Sr . Data Scientist', 'Senior Data Scientist Payments', 'Senior Data Scientist (R Programming)', 'Lead Data Scientist', 'Data Scientist/Senior Data Scientist - Python', 'Senior Data Scientist - Python/Machine Learning Algorithms', 'Data Scientist / Analyst', 'Need Data scientists and data engineers - WFH- less than 30days notice']\n",
      "\n",
      "\n",
      "['Bangalore', 'Kolkata, Hyderabad', 'Bangalore', 'Bangalore', 'Remote', 'Bangalore', 'Bangalore', 'Mumbai, Hyderabad', 'Bangalore', 'Hyderabad']\n",
      "\n",
      "\n",
      "['Uber', 'HCL', 'Visa', 'AirSeva', 'Ignitho', 'Kyndryl', 'ApicalGo Consultancy', 'Altimax Business Solutions', 'open data fabric', 'Covalense Technologies Private Limited']\n",
      "\n",
      "\n",
      "10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Uber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HCL Tech Opening - Lead Data Scientist</td>\n",
       "      <td>Kolkata, Hyderabad</td>\n",
       "      <td>HCL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist Payments</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>AirSeva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist (R Programming)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Ignitho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Kyndryl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist/Senior Data Scientist - Python</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ApicalGo Consultancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - Python/Machine Learnin...</td>\n",
       "      <td>Mumbai, Hyderabad</td>\n",
       "      <td>Altimax Business Solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist / Analyst</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>open data fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Need Data scientists and data engineers - WFH-...</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Covalense Technologies Private Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title        job-location  \\\n",
       "0                                  Sr Data Scientist           Bangalore   \n",
       "1             HCL Tech Opening - Lead Data Scientist  Kolkata, Hyderabad   \n",
       "2                                Sr . Data Scientist           Bangalore   \n",
       "3                     Senior Data Scientist Payments           Bangalore   \n",
       "4              Senior Data Scientist (R Programming)              Remote   \n",
       "5                                Lead Data Scientist           Bangalore   \n",
       "6      Data Scientist/Senior Data Scientist - Python           Bangalore   \n",
       "7  Senior Data Scientist - Python/Machine Learnin...   Mumbai, Hyderabad   \n",
       "8                           Data Scientist / Analyst           Bangalore   \n",
       "9  Need Data scientists and data engineers - WFH-...           Hyderabad   \n",
       "\n",
       "                             company_name  \n",
       "0                                    Uber  \n",
       "1                                     HCL  \n",
       "2                                    Visa  \n",
       "3                                 AirSeva  \n",
       "4                                 Ignitho  \n",
       "5                                 Kyndryl  \n",
       "6                    ApicalGo Consultancy  \n",
       "7              Altimax Business Solutions  \n",
       "8                        open data fabric  \n",
       "9  Covalense Technologies Private Limited  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Then scrape the data for the first 10 jobs results you get.\n",
    "title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "job_title=[]\n",
    "\n",
    "for i in title:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "jtitle=job_title[0:10]\n",
    "print(jtitle)\n",
    "print('\\n')\n",
    "\n",
    "location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "company_location=[]\n",
    "\n",
    "for i in location:\n",
    "    company_location.append(i.text.split('/')[0])\n",
    "    \n",
    "company_location=company_location[0:10]\n",
    "print(company_location)\n",
    "print('\\n')\n",
    "\n",
    "company_name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "name=[]\n",
    "\n",
    "for i in company_name:\n",
    "    name.append(i.text)\n",
    "    \n",
    "name=name[0:10]\n",
    "print(name)\n",
    "print('\\n')\n",
    "\n",
    "print(len(jtitle),len(company_location),len(name))\n",
    "\n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "DS_df=pd.DataFrame()\n",
    "DS_df['job-title']=jtitle\n",
    "DS_df['job-location']=company_location\n",
    "DS_df['company_name']=name\n",
    "\n",
    "DS_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dce210",
   "metadata": {},
   "source": [
    "Q3: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4beb6182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. first get the webpage https://www.naukri.com/\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver\n",
    "url='https://www.naukri.com'\n",
    "driver.get(url)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea812254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "role=driver.find_element_by_class_name('suggestor-input')\n",
    "role.send_keys('Data Scientist')\n",
    "\n",
    "delhi=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input')\n",
    "delhi.send_keys('Delhi/NCR')\n",
    "\n",
    "\n",
    "#3. Then click the search button.\n",
    "search_btn=driver.find_element_by_class_name('qsbSubmit')\n",
    "search_btn.click()\n",
    "# apply salary filter for 3-6lac\n",
    "salary_filter=driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i')\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "74488ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Data scientist- Python', 'Hiring For Senior Data Scientist-Noida', 'Excellent Opportunity For Freshers For AI/ML, Data Scientist, BI, QA', 'Data Analyst / Data Scientist / Business Analytics / Fresher - MNC', 'Data Scientist', 'Data Scientist _NLP', 'Data Scientist (freelance)', 'Data Scientist - MIND Infotech', 'Data Scientist - MIND Infotech', 'Lead Data Scientist']\n",
      "\n",
      "\n",
      "['Gurgaon/Gurugram', 'Noida, New Delhi, Greater Noida', 'Noida, Kolkata, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)\\n(WFH during Covid)', 'Noida, New Delhi, Delhi / NCR', 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR', 'Bangalore/Bengaluru, Delhi / NCR\\n(WFH during Covid)', 'New Delhi, Delhi', 'Noida', 'Noida', 'Delhi / NCR\\n(WFH during Covid)']\n",
      "\n",
      "\n",
      "['TeamPlus Staffing Solution Pvt Ltd', 'Lumiq.ai', 'NTT Data', 'GABA Consultancy services', 'Mount Talent Consulting Private Limited', 'EXL', '2Coms', 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED', 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED', 'Indihire HR Consultants Private Limited']\n",
      "\n",
      "\n",
      "['3-6 Yrs', '2-6 Yrs', '0-0 Yrs', '0-0 Yrs', '1-4 Yrs', '3-8 Yrs', '2-7 Yrs', '4-8 Yrs', '4-8 Yrs', '2-4 Yrs']\n",
      "\n",
      "\n",
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-location</th>\n",
       "      <th>company name</th>\n",
       "      <th>experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data scientist- Python</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>TeamPlus Staffing Solution Pvt Ltd</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist-Noida</td>\n",
       "      <td>Noida, New Delhi, Greater Noida</td>\n",
       "      <td>Lumiq.ai</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent Opportunity For Freshers For AI/ML, ...</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...</td>\n",
       "      <td>NTT Data</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst / Data Scientist / Business Analy...</td>\n",
       "      <td>Noida, New Delhi, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist _NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Delhi / NCR\\n(WFH during Covid)</td>\n",
       "      <td>Indihire HR Consultants Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job-title  \\\n",
       "0                             Data scientist- Python   \n",
       "1             Hiring For Senior Data Scientist-Noida   \n",
       "2  Excellent Opportunity For Freshers For AI/ML, ...   \n",
       "3  Data Analyst / Data Scientist / Business Analy...   \n",
       "4                                     Data Scientist   \n",
       "5                                Data Scientist _NLP   \n",
       "6                         Data Scientist (freelance)   \n",
       "7                     Data Scientist - MIND Infotech   \n",
       "8                     Data Scientist - MIND Infotech   \n",
       "9                                Lead Data Scientist   \n",
       "\n",
       "                                        job-location  \\\n",
       "0                                   Gurgaon/Gurugram   \n",
       "1                    Noida, New Delhi, Greater Noida   \n",
       "2  Noida, Kolkata, Hyderabad/Secunderabad, Pune, ...   \n",
       "3                      Noida, New Delhi, Delhi / NCR   \n",
       "4  Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram...   \n",
       "5  Bangalore/Bengaluru, Delhi / NCR\\n(WFH during ...   \n",
       "6                                   New Delhi, Delhi   \n",
       "7                                              Noida   \n",
       "8                                              Noida   \n",
       "9                    Delhi / NCR\\n(WFH during Covid)   \n",
       "\n",
       "                               company name experience required  \n",
       "0        TeamPlus Staffing Solution Pvt Ltd             3-6 Yrs  \n",
       "1                                  Lumiq.ai             2-6 Yrs  \n",
       "2                                  NTT Data             0-0 Yrs  \n",
       "3                 GABA Consultancy services             0-0 Yrs  \n",
       "4   Mount Talent Consulting Private Limited             1-4 Yrs  \n",
       "5                                       EXL             3-8 Yrs  \n",
       "6                                     2Coms             2-7 Yrs  \n",
       "7  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs  \n",
       "8  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs  \n",
       "9   Indihire HR Consultants Private Limited             2-4 Yrs  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Then scrape the data for the first 10 jobs results you get(job-title, job-location, company name, experience required)\n",
    "title=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "Job_title=[]\n",
    "\n",
    "for i in title:\n",
    "    Job_title.append(i.text)\n",
    "    \n",
    "Job_title=Job_title[0:10]\n",
    "print(Job_title)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "Job_loc=[]\n",
    "for i in location:\n",
    "    Job_loc.append(i.text)\n",
    "    \n",
    "Job_loc=Job_loc[0:10]\n",
    "print(Job_loc)\n",
    "print('\\n')\n",
    "\n",
    "name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "company_name=[]\n",
    "\n",
    "for i in name:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "company_name=company_name[0:10]\n",
    "print(company_name)\n",
    "print('\\n')\n",
    "\n",
    "exp=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "experience=[]\n",
    "\n",
    "for i in exp:\n",
    "    experience.append(i.text)\n",
    "    \n",
    "exp=experience[0:10]\n",
    "print(exp)\n",
    "print('\\n')\n",
    "# check len of array\n",
    "print(len(Job_title),len(Job_loc),len(company_name),len(exp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "\n",
    "DS_df_3_6yearexp=pd.DataFrame()\n",
    "DS_df_3_6yearexp['job-title']=Job_title\n",
    "DS_df_3_6yearexp['job-location']=Job_loc\n",
    "DS_df_3_6yearexp['company name']=company_name\n",
    "DS_df_3_6yearexp['experience required']=exp\n",
    "\n",
    "DS_df_3_6yearexp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ea6ccd",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands andmore” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the\n",
    "required data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3d71996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c465258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for sunglases\n",
    "sunglass_page=driver.find_element_by_class_name('_3704LK')\n",
    "sunglass_page.send_keys('sunglasses')\n",
    "\n",
    "search_clik=driver.find_element_by_class_name('_34RNph')\n",
    "search_clik.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "e94e5773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #creating the empty list\n",
    "import time\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\" or @class=\"IRpwTa _2-ICcC\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))       \n",
    "# create the df for 100 sunglasses      \n",
    "sunglasses_df=pd.DataFrame()\n",
    "sunglasses_df['Brand']=brand[0:100]\n",
    "sunglasses_df['Product Description']=description[0:100]\n",
    "sunglasses_df['Price']=price[0:100]\n",
    "\n",
    "sunglasses_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f3cef1",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link\n",
    "\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\"\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "df314413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open webdriver and flipkaty iphone product page and click the view more reviews\n",
    "\n",
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace')\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a/div/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ae158102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat empty list for all the attributes\n",
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=15\n",
    "\n",
    "#scrape the 15 pages reviews\n",
    "\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in ratings:\n",
    "        Rating.append(i.text)\n",
    "    reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    for i in reviews:\n",
    "        Review_summary.append(i.text)\n",
    "    full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for i in full_reviews:\n",
    "        Full_review.append(i.text)\n",
    "    next_button=driver.find_elements_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(next_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_button[0].get_attribute('href'))\n",
    "\n",
    "#creart the df\n",
    "iphone_reviews=pd.DataFrame()\n",
    "iphone_reviews['Rating']=Rating[0:100]\n",
    "iphone_reviews['Review_summary']=Review_summary[0:100]\n",
    "iphone_reviews['Full_review']=Full_review[0:100]\n",
    "\n",
    "iphone_reviews.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad6405",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d8e45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.flipkart.com/'\n",
    "web_driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "51d65ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the key word as sneaker and search\n",
    "enter_key=web_driver.find_element_by_class_name('_3704LK')\n",
    "enter_key.send_keys('sneakers')\n",
    "web_driver.find_element_by_class_name('L0Z3Pu').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c6f1499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list \n",
    "brand=[]\n",
    "Product_Description=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=10\n",
    "\n",
    "for pages in range(start,end):\n",
    "    brands=web_driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "    product_desc=web_driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    for i in product_desc:\n",
    "        Product_Description.append(i.text)\n",
    "    prices=web_driver.find_elements_by_xpath('//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    next_page=web_driver.find_elements_by_xpath('//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        web_driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        web_driver.get(next_page[0].get_attribute('href'))\n",
    "        \n",
    "#create a df \n",
    "sneaker_df=pd.DataFrame()\n",
    "sneaker_df['Brand']=brand[0:100]\n",
    "sneaker_df['Product_Description']=Product_Description[0:100]\n",
    "sneaker_df['Price']=price[0:100]\n",
    "\n",
    "sneaker_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49ea47",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47df0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "url='https://www.myntra.com/shoes'\n",
    "driver.get(url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e7e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price_filter=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_filter.click() \n",
    "color_filter=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "color_filter.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b6da6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "brands=[]\n",
    "short_description=[]\n",
    "prices=[]\n",
    "\n",
    "start=0\n",
    "end=2\n",
    "\n",
    "for page in range(start,end):\n",
    "    brand=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "    for i in brand:\n",
    "        brands.append(i.text)\n",
    "    short_desc=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "    for i in short_desc:\n",
    "        short_description.append(i.text)\n",
    "    price=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "    for i in price:\n",
    "        prices.append(i.text)\n",
    "    next_page=driver.find_elements_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a')\n",
    "    try:\n",
    "        driver.get(next_page[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(next_page[0].get_attribute('href'))\n",
    "    \n",
    "        \n",
    "        \n",
    "#create df \n",
    "shoes_df=pd.DataFrame()\n",
    "shoes_df['Brand']=brands[0:100]\n",
    "shoes_df['short_description']=short_description[0:100]\n",
    "shoes_df['prices']=prices[0:100]\n",
    "\n",
    "shoes_df.shape\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
