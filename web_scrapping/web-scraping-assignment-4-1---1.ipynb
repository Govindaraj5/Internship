{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException,TimeoutException\n",
    "import requests\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b46b9",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chrome dirver\n",
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784989a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creare the temp list to store the value from iteration\n",
    "temp_list=[]\n",
    "# set the first value to fetch from the element table \n",
    "r=1\n",
    "# set 1 has to end the while loop complete once all the element is scrapped\n",
    "while(1):\n",
    "    # extract all the required value from element table from the page\n",
    "    try:   \n",
    "        video_name=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr['+str(r)+']/td[2]').text.replace('\"','')\n",
    "        Artist_name=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr['+str(r)+']/td[3]').text.replace('\"','')\n",
    "        Rank=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr['+str(r)+']/td[1]').text.replace('\"','')\n",
    "        View=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr['+str(r)+']/td[4]').text.replace('\"','')\n",
    "        update_date=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]/tbody/tr['+str(r)+']/td[5]').text.replace('\"','')\n",
    "        \n",
    "         # store the every iteration value into dic \n",
    "        Table_dict = {'Rank':Rank,'video_name': video_name,'Artist_name':Artist_name,'View':View,'update_date':update_date}\n",
    "        \n",
    "        #append the dictionry into to empty list\n",
    "        temp_list.append(Table_dict)\n",
    "        # create the dataframe\n",
    "        df=pd.DataFrame(temp_list)\n",
    "        r=r+1\n",
    "    # if element is not there then replace '-' and break the loop once done\n",
    "    except NoSuchElementException:\n",
    "        temp_list.append('-')\n",
    "        break\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0769961",
   "metadata": {},
   "source": [
    "2. Scrape the details teamIndiaâ€™sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://www.bcci.tv/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74f8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on international \n",
    "\n",
    "internation=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "internation.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a72340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the match title \n",
    "title=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div/div/div/div[1]/h5').text\n",
    "\n",
    "# scrape place \n",
    "ground=driver.find_element(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]').text\n",
    "place=driver.find_element(By.XPATH,'//span[@class=\"ng-binding\"]').text\n",
    "\n",
    "match_place=ground+place\n",
    "match_place\n",
    "\n",
    "# scrape date and time\n",
    "date=driver.find_element(By.XPATH,'//div[@class=\"match-dates ng-binding\"]').text\n",
    "#scrape time\n",
    "time=driver.find_element(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]').text\n",
    "\n",
    "# create the data frame\n",
    "\n",
    "df=pd.DataFrame({'Match_title':[title],'Place':[match_place],'Date':[date],'Time':[time]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf3b1a5",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d910273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('http://statisticstimes.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88424fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indian_economy=driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]')\n",
    "#indian_economy.click()\n",
    "l=[]\n",
    "\n",
    "button=driver.find_elements(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div')\n",
    "\n",
    "for i in button:\n",
    "    b=i.get_attribute('href')\n",
    "    l.append(b)\n",
    "    \n",
    "#time.sleep(1)\n",
    "#driver.execute_script(\"arguments[2].click();\", button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e85e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_btns = driver.find_elements(By.XPATH, '//div[@class=\"dropdown\" and contains(text(), \"india\")]')\n",
    "\n",
    "for btn in more_btns:\n",
    "    try:\n",
    "        driver.implicitly_wait(10)\n",
    "        ActionChains(driver).move_to_element(btn).click(button).perform()\n",
    "    except:\n",
    "        print('ERROR using ActionChains(driver).move_to_element(btn).click(button).perform()')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bda4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]/option[text()=\"india\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0ef6c",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://github.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ad4a2",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://www.billboard.com/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94baa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "btn.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace56c06",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b7f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "\n",
    "r=1\n",
    "while(1):\n",
    "    \n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr['+str(r)+']/td[2]').text\n",
    "        auther=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr['+str(r)+']/td[3]').text\n",
    "        sales=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr['+str(r)+']/td[4]').text\n",
    "        publisher=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr['+str(r)+']/td[5]').text\n",
    "        Genre=driver.find_element(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr['+str(r)+']/td[6]').text\n",
    "        \n",
    "        books={'Title':name,'Auther':auther,'Volume_sold':sales,'Publisher':publisher,'Genre':Genre}        \n",
    "         # store in list\n",
    "        ls.append(books)\n",
    "         # create the df   \n",
    "        df=pd.DataFrame(ls)\n",
    "         # iterate the row number\n",
    "        r=r+1\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    \n",
    "        \n",
    "df                                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec0e1f",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6eed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Year_span=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "r=1\n",
    "while(1):\n",
    "    # scrap the title,year,Ratings,votes\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div['+str(r)+']/div[2]/h3/a')\n",
    "        Title.append(name.text)\n",
    "        year=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div['+str(r)+']/div[2]/h3/span[2]')\n",
    "        Year_span.append(year.text)\n",
    "        Rat=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div['+str(r)+']/div[2]/div[1]/div[1]/span[2]')\n",
    "        Ratings.append(Rat.text)\n",
    "        vot=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div['+str(r)+']/div[2]/p[4]/span[2]')\n",
    "        Votes.append(vot.text)\n",
    "        r=r+1\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the Genre,Run_time\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "\n",
    "gen=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "for i in gen:\n",
    "    Genre.append(i.text)  \n",
    "            \n",
    "time=driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')\n",
    "for i in time:\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "dic={'Title':Title,'Year_span':Year_span,'Genre':Genre,'Run_time':Run_time,'Ratings':Ratings,'Votes':Votes}  \n",
    "\n",
    "df1=pd.DataFrame(dic)\n",
    "\n",
    "df1\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc998910",
   "metadata": {},
   "source": [
    "8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8f51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://archive.ics.uci.edu/ml/index.php')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5352fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on all data set link\n",
    "data_sets=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "data_sets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67563e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Data_types=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "r=2\n",
    "while(1):\n",
    "    # scrap the datea\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[1]/table/tbody/tr/td[2]/p/b/a')\n",
    "        Name.append(name.text)\n",
    "        types=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[2]/p')\n",
    "        Data_types.append(types.text)\n",
    "        task=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[3]/p')\n",
    "        Task.append(task.text)\n",
    "        attr=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[4]/p')\n",
    "        Attribute_type.append(attr.text)\n",
    "        instances=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[5]/p')\n",
    "        No_of_instances.append(instances.text)\n",
    "        attr_no=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[6]/p')\n",
    "        No_of_attribute.append(attr_no.text)\n",
    "        year=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr['+str(r)+']/td[7]/p')\n",
    "        Year.append(year.text)\n",
    "        \n",
    "        r=r+1\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        break\n",
    "        \n",
    "# create the dataframe\n",
    "\n",
    "dic={'Name':Name,'Data_types':Data_types,'Task':Task,'Attribute_type':Attribute_type,\n",
    "                'No_of_instances':No_of_instances,'No_of_attribute':No_of_attribute,'Year':Year}\n",
    "df=pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc2af8",
   "metadata": {},
   "source": [
    " 9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e1018ade",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom target frame detached\n  (Session info: chrome=112.0.5615.138)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00C3DCE3]\n\t(No symbol) [0x00BD39D1]\n\t(No symbol) [0x00AE4C70]\n\t(No symbol) [0x00AD7E87]\n\t(No symbol) [0x00AD6BF6]\n\t(No symbol) [0x00AD747A]\n\t(No symbol) [0x00AE022F]\n\t(No symbol) [0x00AEA348]\n\t(No symbol) [0x00AECD46]\n\t(No symbol) [0x00AD77D3]\n\t(No symbol) [0x00AEA055]\n\t(No symbol) [0x00B3D779]\n\t(No symbol) [0x00B2ACC6]\n\t(No symbol) [0x00B06F68]\n\t(No symbol) [0x00B080CD]\n\tGetHandleVerifier [0x00EB3832+2506274]\n\tGetHandleVerifier [0x00EE9794+2727300]\n\tGetHandleVerifier [0x00EEE36C+2746716]\n\tGetHandleVerifier [0x00CE6690+617600]\n\t(No symbol) [0x00BDC712]\n\t(No symbol) [0x00BE1FF8]\n\t(No symbol) [0x00BE20DB]\n\t(No symbol) [0x00BEC63B]\n\tBaseThreadInitThunk [0x769E6B89+25]\n\tRtlGetFullPathName_UEx [0x778A8F9F+1215]\n\tRtlGetFullPathName_UEx [0x778A8F6D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21436/1055975790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# open new chrom and wbesite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.naukri.com/hr-recruiters-consultants'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom target frame detached\n  (Session info: chrome=112.0.5615.138)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00C3DCE3]\n\t(No symbol) [0x00BD39D1]\n\t(No symbol) [0x00AE4C70]\n\t(No symbol) [0x00AD7E87]\n\t(No symbol) [0x00AD6BF6]\n\t(No symbol) [0x00AD747A]\n\t(No symbol) [0x00AE022F]\n\t(No symbol) [0x00AEA348]\n\t(No symbol) [0x00AECD46]\n\t(No symbol) [0x00AD77D3]\n\t(No symbol) [0x00AEA055]\n\t(No symbol) [0x00B3D779]\n\t(No symbol) [0x00B2ACC6]\n\t(No symbol) [0x00B06F68]\n\t(No symbol) [0x00B080CD]\n\tGetHandleVerifier [0x00EB3832+2506274]\n\tGetHandleVerifier [0x00EE9794+2727300]\n\tGetHandleVerifier [0x00EEE36C+2746716]\n\tGetHandleVerifier [0x00CE6690+617600]\n\t(No symbol) [0x00BDC712]\n\t(No symbol) [0x00BE1FF8]\n\t(No symbol) [0x00BE20DB]\n\t(No symbol) [0x00BEC63B]\n\tBaseThreadInitThunk [0x769E6B89+25]\n\tRtlGetFullPathName_UEx [0x778A8F9F+1215]\n\tRtlGetFullPathName_UEx [0x778A8F6D+1165]\n"
     ]
    }
   ],
   "source": [
    "# load the chrome dirver\n",
    "driver=webdriver.Chrome('C:\\\\Users\\\\Hp\\\\OneDrive\\\\Desktop\\\\intership\\\\chromedriver_win32 (1)\\\\chromedriver.exe')\n",
    "# open new chrom and wbesite \n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320445f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.send_keys('Data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire_for=[]\n",
    "Location=[]\n",
    "\n",
    "# extract name\n",
    "try:\n",
    "    n=driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]')\n",
    "    for i in n:\n",
    "        Name.append(i.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "    \n",
    "    \n",
    "# extract Designation\n",
    "try:\n",
    "    n=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "    for i in n:\n",
    "        Designation.append(i.text)\n",
    "except:\n",
    "    Designation.append('-')\n",
    "    \n",
    "# extract Company\n",
    "try:\n",
    "    n=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]')\n",
    "    for i in n:\n",
    "        Company.append(i.text)\n",
    "except:\n",
    "    Company.append('-')\n",
    "\n",
    "# extract Skills_they_hire_for\n",
    "try:\n",
    "    n=driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in n:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "except:\n",
    "    Skills_they_hire_for.append('-')\n",
    "    \n",
    "# extract Location\n",
    "try:\n",
    "    n=driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]')\n",
    "    for i in n:\n",
    "        Location.append(i.text)\n",
    "except:\n",
    "    Location.append('-')\n",
    "        \n",
    "\n",
    "# create the dataframe\n",
    "df=pd.DataFrame({'Name':Name,'Designation':Designation,'Company':Company,\n",
    "                 'Skills_they_hire_for':Skills_they_hire_for,'Location':Location})  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
