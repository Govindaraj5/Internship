{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required library\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90f061",
   "metadata": {},
   "source": [
    "#1) Write a python program to display all the header tags from wikipedia.org and make data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c272e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request to the page to exteract the data\n",
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "#page\n",
    "# load the page content using BS\n",
    "soup=BeautifulSoup(page.text,\"html.parser\")\n",
    "#soup\n",
    "Title=[]\n",
    "for i in soup.find_all('h2',class_='mp-h2'):\n",
    "    Title.append(i.text)\n",
    "Title\n",
    "\n",
    "Title_df=pd.DataFrame({'header':Title})\n",
    "Title_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6d1cf6",
   "metadata": {},
   "source": [
    "#2) Write a python program to display IMDB’s Top rated 50 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57dcc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    " \n",
    " \n",
    "url = 'http://www.imdb.com/chart/top'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    " \n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    " \n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, 50):\n",
    "     \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = {\"name\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year_of_release\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64751770",
   "metadata": {},
   "source": [
    "3) Write a python program to display IMDB’s Top rated 50 Indian movies’ data (i.e. name, rating, year of \n",
    "release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b416b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    " \n",
    " \n",
    "url = 'https://www.imdb.com/india/top-rated-indian-movies/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "movies = soup.select('td.titleColumn')\n",
    "ratings = [b.attrs.get('data-value')\n",
    "        for b in soup.select('td.posterColumn span[name=ir]')]\n",
    " \n",
    "# create a empty list for storing\n",
    "# movie information\n",
    "list = []\n",
    " \n",
    "# Iterating over movies to extract\n",
    "# each movie's details\n",
    "for index in range(0, 50):\n",
    "     \n",
    "    # Separating movie into: 'place',\n",
    "    # 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    data = {\"name\": movie_title,\n",
    "            \"rating\": ratings[index],\n",
    "            \"year_of_release\": year,\n",
    "            }\n",
    "    list.append(data)\n",
    "\n",
    "df = pd.DataFrame(list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e5b2e",
   "metadata": {},
   "source": [
    "4) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://presidentofindia.nic.in/former-presidents.htm'\n",
    "r=requests.get(url)\n",
    "r\n",
    "soup=BeautifulSoup(r.text,\"html.parser\")\n",
    "soup\n",
    "l=[]\n",
    "for i in soup.find_all('div',class_='presidentListing'):\n",
    "    name=i.text.split('\\n')[1]\n",
    "    Term_ofoffice=i.text.split('\\n')[2].replace('Term of Office:','')\n",
    "    data={\"President_name\":name,\"Term_ofoffice\":Term_ofoffice}\n",
    "    l.append(data)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(l)\n",
    "df   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017209e",
   "metadata": {},
   "source": [
    "5) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "c) Top 10 ODI bowlers along with the records of their team andrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) Top 10 ODI teams in men’s cricket(odi) along with the records for matches, points and rating. \n",
    "url='https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup   \n",
    "\n",
    "result=soup.find_all('tr')\n",
    "team=[]\n",
    "for i in range(1,11):\n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    team_name=list1[1]\n",
    "    matches=list1[3]\n",
    "    points=list1[4]\n",
    "    rating=list1[5]\n",
    "    \n",
    "    \n",
    "    data={'Rank':Rank,'Team_Name':team_name,'Matches':matches,'Points':points,'Ratings':rating}\n",
    "    team.append(data)\n",
    "    \n",
    "df=pd.DataFrame(team)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48416b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b) Top 10 ODI Batsmen along with the records of their team and rating\n",
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup \n",
    "# first player data\n",
    "first_data=soup.find(\"div\",class_=\"rankings-block__top-player\")\n",
    "text=[x.strip() for x in first_data.text.split('\\n') if x]\n",
    "Rank=text[0]\n",
    "Name=text[3]\n",
    "country=text[4]\n",
    "Rating=text[5]\n",
    "data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "\n",
    "# other player data\n",
    "result=soup.find_all('tr',class_='table-body')\n",
    "player=[]\n",
    "# first append the first player data\n",
    "player.append(data)\n",
    "for i in range(0,9):\n",
    "   \n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    Name=list1[3]\n",
    "    country=list1[4]\n",
    "    Rating=list1[5]\n",
    "\n",
    "    \n",
    "    # appending rest of the players data\n",
    "    data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "    player.append(data)\n",
    "    \n",
    "df=pd.DataFrame(player)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fe48e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #c) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "url='https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup \n",
    "# first player data\n",
    "first_data=soup.find(\"tr\",class_=\"rankings-block__banner\")\n",
    "text=[x.strip() for x in first_data.text.split('\\n') if x]\n",
    "Rank=text[0]\n",
    "Name=text[3]\n",
    "country=text[4]\n",
    "Rating=text[5]\n",
    "data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "\n",
    "# other player data\n",
    "result=soup.find_all('tr',class_='table-body')\n",
    "player=[]\n",
    "# first append the first player data\n",
    "player.append(data)\n",
    "for i in range(0,9):\n",
    "   \n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    Name=list1[3]\n",
    "    country=list1[4]\n",
    "    Rating=list1[5]\n",
    "\n",
    "    \n",
    "    # appending rest of the players data\n",
    "    data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "    player.append(data)\n",
    "    \n",
    "df=pd.DataFrame(player)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3599ea61",
   "metadata": {},
   "source": [
    "6) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b20958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a) a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. \n",
    "url='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup   \n",
    "\n",
    "result=soup.find_all('tr')\n",
    "team=[]\n",
    "for i in range(1,11):\n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    team_name=list1[1]\n",
    "    matches=list1[3]\n",
    "    points=list1[4]\n",
    "    rating=list1[5]\n",
    "    \n",
    "    \n",
    "    data={'Rank':Rank,'Team_Name':team_name,'Matches':matches,'Points':points,'Ratings':rating}\n",
    "    team.append(data)\n",
    "    \n",
    "df=pd.DataFrame(team)\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    " # b) Top 10 women’s ODI Batting players along with the records of their team and rating. \n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/Batting'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup \n",
    "# first player data\n",
    "first_data=soup.find(\"tr\",class_=\"rankings-block__banner\")\n",
    "text=[x.strip() for x in first_data.text.split('\\n') if x]\n",
    "Rank=text[0]\n",
    "Name=text[3]\n",
    "country=text[4]\n",
    "Rating=text[5]\n",
    "data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "\n",
    "# other player data\n",
    "result=soup.find_all('tr',class_='table-body')\n",
    "player=[]\n",
    "# first append the first player data\n",
    "player.append(data)\n",
    "for i in range(0,9):\n",
    "   \n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    Name=list1[3]\n",
    "    country=list1[4]\n",
    "    Rating=list1[5]\n",
    "\n",
    "    \n",
    "    # appending rest of the players data\n",
    "    data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "    player.append(data)\n",
    "    \n",
    "df=pd.DataFrame(player)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f97ade",
   "metadata": {},
   "outputs": [],
   "source": [
    " #c) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "url='https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "response=requests.get(url)\n",
    "response\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup \n",
    "# first player data\n",
    "first_data=soup.find(\"tr\",class_=\"rankings-block__banner\")\n",
    "text=[x.strip() for x in first_data.text.split('\\n') if x]\n",
    "Rank=text[0]\n",
    "Name=text[3]\n",
    "country=text[4]\n",
    "Rating=text[5]\n",
    "data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "\n",
    "# other player data\n",
    "result=soup.find_all('tr',class_='table-body')\n",
    "player=[]\n",
    "# first append the first player data\n",
    "player.append(data)\n",
    "for i in range(0,9):\n",
    "   \n",
    "    list1=[x.strip() for x in result[i].text.split('\\n') if x]\n",
    "    Rank=list1[0]\n",
    "    Name=list1[3]\n",
    "    country=list1[4]\n",
    "    Rating=list1[5]\n",
    "\n",
    "    \n",
    "    # appending rest of the players data\n",
    "    data={'Rank':Rank,'Player_Name':Name,'country':country,'Ratings':Rating}\n",
    "    player.append(data)\n",
    "    \n",
    "df=pd.DataFrame(player)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756920ae",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and \n",
    "make data frame\u0002\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6862791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "url='https://www.cnbc.com/world/?region=world'\n",
    "response=requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8adb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439212e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headline=[] \n",
    "\n",
    "for i in soup.find_all('div',class_='LatestNews-headlineWrapper'):\n",
    "    title=re.sub(r'.',' ',i.text,count=12)\n",
    "    headline.append(title.strip()) \n",
    "time=[]\n",
    "    \n",
    "for i in soup.find_all('time',class_='LatestNews-timestamp'):\n",
    "    time.append(i.text.strip()) \n",
    "len(time) \n",
    "\n",
    "url=[]\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    url.append(i.get('href')) \n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Title':headline,'update_time':time,'url':url})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73975356",
   "metadata": {},
   "source": [
    "8.Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame\n",
    "i) Paper Title\n",
    "ii) Authors\n",
    "iii) Published_Date\n",
    "iv) Paper URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3538db",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response=requests.get(url)\n",
    "response\n",
    "\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    t.append(i.text)\n",
    "auther=[]\n",
    "for i in soup.find_all(\"span\",class_='sc-1w3fpd7-0 dnCnAO'):\n",
    "    auther.append(i.text)\n",
    "\n",
    "date=[]\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text)\n",
    "len(date)\n",
    "\n",
    "url=[]\n",
    "for i in soup.find_all('a',class_='sc-5smygv-0 fIXTHm'):\n",
    "    url.append(i.get('href'))\n",
    "    \n",
    "df=pd.DataFrame({'Paper_Title':t,'Auther':auther,'Published_Date':date,'Paper_URL':url})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe202d65",
   "metadata": {},
   "source": [
    "9) Write a python program to scrape mentioned details from dineout.co.in and make data frame\u0002\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96faa7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.text,'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "for i in soup.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "menu=[]\n",
    "price=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    x=i.text.split(\"|\")\n",
    "    menu.append(x[1])\n",
    "    price.append(x[0])\n",
    "\n",
    "    \n",
    "\n",
    "image=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    image.append(i.get('data-src'))\n",
    "\n",
    "\n",
    "location=[]\n",
    "\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(i.text)\n",
    "\n",
    "df=pd.DataFrame({\"Restaurant_name\":title,\"Cuisine\":name,\"Location\":location,\"Ratings\":rating,\"Image_URL\":image})\n",
    "df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857210ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
